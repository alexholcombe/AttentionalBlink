---
title: "effect of number of fits"
author: "Alex Holcombe"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import data as a test case - backwards paper 2, E1

```{r importData, echo=FALSE, message=FALSE}
#rm(list=ls())

#Compensate for path getting set to mixtureModeling/tests/
if (basename(getwd()) != "tests") {
  pathNeeded<- "mixtureModeling"
} else { 
  pathNeeded <- ".." 
}

#path<-file.path(pathNeeded,"tests")
#print(getwd())
#print(list.files(path))
path<-'.'
filename<-file.path(path,"manyFits.Rdata")
print( file.exists(filename) )
load(filename, verbose=TRUE) #So can be used by Part2 to sample different subsets to get a sense of SD of mean for different subset sizes


```

manyFits contains results of fitting each condition 100 times.

Determine the empirical SD of the mean of `n` fits by looking at the SD of the mean for different `n`s of fits.

In other words for each `n` up to `reps`, take random samples of n from the replicates and
calculate the mean. We want to know the sd of the sampling distribution of that mean (the expected se). So we repeat the sampling many times and calculate the mean each time, and the sd of all those means.

Do it separately for each condition and then average the SEs of the conditions.

Define the functions needed first.

```{r functions for SE, echo=FALSE, message=FALSE}

#Define functions will need 

setOfFitsMean<- function(df,reps,numFitsForMean) {
  #Take a random subset of numFitsForMean fits and calculate the parameters' mean 
  whichFits<- sample(seq(1:reps), numFitsForMean, replace = TRUE)
  these<- filter(df, replicate == whichFits) #grab those particular fits
  #Calculate the mean fit for each condition for these
  meanThese<- these %>% group_by(subject,target,condition) %>%
          summarise_at( .vars = c("efficacy", "latency","precision"),  .funs = c(Mean="mean") )
  return(meanThese) #the mean for each condition
}

bootstrap_FitSE<- function(dg,numFitsForMean, bootstrapSamples) {
  #Bootstrap the SE from the mean. That is, with replacement take sets of fits, calculate the mean parameter estimate for each, and take the SD of those results, which is the SE of fitting for that setsize.
  #For a particular numFitsForMean, calculate the mean SD across many (bootstrapSamples) virtual fitting sessions. 
  #dg contains the result of 100 fits for each condition. A virtual fitting session is a subsample of 
  # numFitsForMean of those 100.
  eachSetsMean<- data.frame()
  reps<-max(dg$replicate)
  for (sampleI in 1:bootstrapSamples) {
    oneSetOfFitsMean<- setOfFitsMean(dg,reps,numFitsForMean)
    eachSetsMean<- rbind(eachSetsMean,data.frame(oneSetOfFitsMean))
  }
  #Now we have lots of mean fits for each condition. Calculate their SD, which is the SE for this numFitsForMean
  SE<- eachSetsMean %>% group_by(subject,target,condition) %>% summarise_at( .vars = c("efficacy_Mean", "latency_Mean","precision_Mean"),
                                .funs = c(SE="sd") )
  return(SE)
}

```

Try the bootstrap_FitSE once as a test, for sets of 20 fits, and show just one condition where SE happens to be very small.

```{r test bootstrap, echo=FALSE, message=FALSE}
bootstrapSampleN<-20
numFitsForMean=2
SEeachCondition<- bootstrap_FitSE(manyFits, numFitsForMean, bootstrapSampleN)
SEeachCondition<- data.frame(SEeachCondition)
#calculate the mean of SEeachCondition to get the mean SE across conditions
SE<-SEeachCondition %>% summarise_at( .vars = c("efficacy_Mean_SE", "latency_Mean_SE","precision_Mean_SE"),
                                .funs = c(m="mean") )
print(SE) #These look insanely small for only two fits.

#Compare to AA 1 1 that did in part 1
SEeachCondition %>% dplyr::filter(subject=="AA",condition==1,target==1)
```




```{r empiricalSE, echo=FALSE, message=FALSE}
allTheFitSets<- data.frame()
for (numFitsThis in seq(1,50,5)) {
  SEeachCondition<- bootstrap_FitSE(manyFits, numFitsThis, bootstrapSampleN)
  SEeachCondition$nFits<-numFitsThis
  allTheFitSets<- rbind(allTheFitSets, data.frame(SEeachCondition))
}
#"longer object length is not a multiple of shorter object length" is not a problem I don't think, it is generated
# by the filter(df, replicate == whichFits) command

allTheFitSets<- data.frame(allTheFitSets)
#calculate the mean of SEeachCondition to get the mean SE across conditions
SE<-allTheFitSets %>% group_by(nFits) %>% summarise_at( .vars = c("efficacy_Mean_SE", "latency_Mean_SE","precision_Mean_SE"),
                                .funs = c(m="mean") )

print(SE)

```

WOW! It does not go down with nFits, which either means there's something wrong with my code, or that the fits are just too non-independent and heavy-tailed because of pesky multimodal distributions perhaps.

Check whether there is any condition with high variation - standard deviation greater than .05

```{r bad conditions, echo=FALSE, message=FALSE}
filter_at( w, vars(ends_with("Sd")), any_vars(. > .05) )

```
